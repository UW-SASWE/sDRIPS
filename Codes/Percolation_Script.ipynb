{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  MeanSoilMoisture  MeanPercolation  MeanFieldCapacity  \\\n",
      "0     2023-01-04          0.304932         0.024472           0.313823   \n",
      "1     2023-01-07          0.577484         0.265435           0.313823   \n",
      "2     2023-01-11          0.583333         0.270504           0.313823   \n",
      "3     2023-01-16          0.290589         0.019735           0.313823   \n",
      "4     2023-01-19          0.575083         0.261556           0.313823   \n",
      "...          ...               ...              ...                ...   \n",
      "5705  2023-05-11          0.416869         0.112277           0.303802   \n",
      "5706  2023-05-16          0.205611         0.008822           0.303802   \n",
      "5707  2023-05-19          0.600000         0.294907           0.303802   \n",
      "5708  2023-05-23          0.600000         0.295463           0.303802   \n",
      "5709  2023-05-28          0.466889         0.161585           0.303802   \n",
      "\n",
      "               RegionID  \n",
      "0              T1S1B_95  \n",
      "1              T1S1B_95  \n",
      "2              T1S1B_95  \n",
      "3              T1S1B_95  \n",
      "4              T1S1B_95  \n",
      "...                 ...  \n",
      "5705  Dinajpur_Canal_69  \n",
      "5706  Dinajpur_Canal_69  \n",
      "5707  Dinajpur_Canal_69  \n",
      "5708  Dinajpur_Canal_69  \n",
      "5709  Dinajpur_Canal_69  \n",
      "\n",
      "[5710 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define parameters\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-05-31'\n",
    "chunk_size_days = 30  # Each chunk is 30 days long\n",
    "\n",
    "# Load the shapefile and convert to a feature collection\n",
    "# roi_fc = geemap.shp_to_ee('../TBP Shape Files/Gross Command Area.shp')\n",
    "roi_fc = ee.FeatureCollection('users/skhan7/PhD/Chapter2/BWDB_Commad_Area_Simplified_Modified2')\n",
    "field_capacity = ee.Image(\"OpenLandMap/SOL/SOL_WATERCONTENT-33KPA_USDA-4B1C_M/v01\").select('b10').divide(ee.Number(100)).clip(roi_fc)\n",
    "# Function to upscale soil moisture to 250m resolution\n",
    "def upscale_to_250m(image,region):\n",
    "    return image.reduceResolution(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        bestEffort=True,\n",
    "        geometry = region.geometry()\n",
    "    ).reproject(crs=image.projection(), scale=250)\n",
    "\n",
    "# Function to calculate soil moisture for each image within a given region\n",
    "def calculate_soil_moisture(image, wet_index, dry_index, urban_mask, water_mask, region):\n",
    "    sensitivity = wet_index.subtract(dry_index)\n",
    "    Mv = image.select('VV').subtract(dry_index).divide(sensitivity)\n",
    "    Mv = Mv.updateMask(water_mask.Not()).updateMask(urban_mask.Not())\n",
    "    Mv_upscaled = Mv.reduceResolution(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        bestEffort=True,\n",
    "    ).reproject(crs=Mv.projection(), scale=250)\n",
    "    # Calculate mean soil moisture for each image in the specified region\n",
    "    Mv_upscaled_clamped = Mv_upscaled.clamp(0, 0.6)\n",
    "    mean_ssm = Mv_upscaled_clamped.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=region.geometry(),\n",
    "        scale=250,\n",
    "        maxPixels=1e9\n",
    "    ).get('VV')\n",
    "    percolation = Mv_upscaled_clamped.subtract(field_capacity).max(0)\n",
    "    mean_percolation = percolation.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=region.geometry(),\n",
    "        scale=250,\n",
    "        maxPixels=1e9\n",
    "    ).get('VV')\n",
    "    mean_fieldCapacity= field_capacity.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=region.geometry(),\n",
    "        scale=250,\n",
    "        maxPixels=1e9\n",
    "    ).get('b10')\n",
    "\n",
    "    # Get the date of the image\n",
    "    date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd')\n",
    "    \n",
    "    return ee.Feature(None, {'date': date, 'MeanSoilMoisture': mean_ssm, 'MeanPercolation': mean_percolation, 'MeanFieldCapacity': mean_fieldCapacity,'RegionID': region.get('CNLNM_ID')})\n",
    "\n",
    "# Generate a list of start and end dates for each 30-day chunk\n",
    "start_date_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_date_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "dates = pd.date_range(start=start_date_dt, end=end_date_dt, freq=f'{chunk_size_days}D')\n",
    "\n",
    "# Initialize a list to store dataframes for each region\n",
    "region_dataframes = []\n",
    "\n",
    "# Iterate over each region (feature) in the ROI feature collection\n",
    "for region in roi_fc.toList(roi_fc.size()).getInfo():\n",
    "    region_feature = ee.Feature(region)\n",
    "    region_id = region_feature.get('CNLNM_ID').getInfo()  # Use 'CNLNMID' as the region ID\n",
    "\n",
    "    # Process each 30-day chunk for the current region\n",
    "    all_results = []\n",
    "    for i in range(len(dates) - 1):\n",
    "        chunk_start = dates[i].strftime('%Y-%m-%d')\n",
    "        chunk_end = dates[i + 1].strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Load Sentinel-1 Image Collection for the current chunk\n",
    "        s1_collection_chunk = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "                               .filterBounds(region_feature.geometry())\n",
    "                               .filterDate(chunk_start, chunk_end)\n",
    "                               .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "                               .select(['VV']))\n",
    "        \n",
    "        # Calculate wet and dry indices for the current chunk\n",
    "        wet_index = s1_collection_chunk.max().select('VV')\n",
    "        dry_index = s1_collection_chunk.min().select('VV')\n",
    "        \n",
    "        # Define urban and water masks\n",
    "        avg_vv = s1_collection_chunk.mean().select('VV')\n",
    "        urban_mask = avg_vv.gt(-6)  # Urban: VV > -6 dB\n",
    "        water_mask = avg_vv.lt(-17)  # Water: VV < -17 dB\n",
    "        \n",
    "        # Calculate SSM for each image in the chunk for the current region\n",
    "        soil_moisture_features = s1_collection_chunk.map(\n",
    "            lambda image: calculate_soil_moisture(image, wet_index, dry_index, urban_mask, water_mask, region_feature)\n",
    "        )\n",
    "        \n",
    "        # Retrieve SSM values from each image in the chunk\n",
    "        ssm_features = soil_moisture_features.getInfo()\n",
    "        chunk_data = [{'Date': f['properties']['date'],\n",
    "                       'MeanSoilMoisture': f['properties']['MeanSoilMoisture'],\n",
    "                       'MeanPercolation': f['properties']['MeanPercolation'],\n",
    "                       'MeanFieldCapacity': f['properties']['MeanFieldCapacity'],\n",
    "                       'RegionID': f['properties']['RegionID']} for f in ssm_features['features']]\n",
    "        \n",
    "        # Append chunk data to all results for the region\n",
    "        all_results.extend(chunk_data)\n",
    "    \n",
    "    # Create a DataFrame for the current region and add it to the list\n",
    "    region_df = pd.DataFrame(all_results)\n",
    "    # region_df['MaxSoilMoisture'] = region_df['MeanSoilMoisture'].max()\n",
    "    region_df['RegionID'] = region_id  # Ensure RegionID is present in DataFrame\n",
    "    # region_df['NormalizedSoilMoisture'] = (region_df['MeanSoilMoisture'].max() - region_df['MeanSoilMoisture'])/region_df['MeanSoilMoisture'].max()\n",
    "    region_dataframes.append(region_df)\n",
    "\n",
    "# Combine all regional dataframes into a single GeoDataFrame\n",
    "final_df = pd.concat(region_dataframes, ignore_index=True)\n",
    "# final_df['MaxSoilMoisture'] = final_df.groupby('RegionID')['MeanSoilMoisture'].transform('max')\n",
    "\n",
    "# Normalize the MeanSoilMoisture for each region\n",
    "# final_df['NormalizedSoilMoisture'] = (final_df['MaxSoilMoisture'] - final_df['MeanSoilMoisture']) / final_df['MaxSoilMoisture']\n",
    "# final_df['NormalizedSoilMoisture'] = (final_df['MeanSoilMoisture']) / final_df['MaxSoilMoisture']\n",
    "# final_df['MeanSoilMoisture'] = final_df['MeanSoilMoisture'].clip(upper=0.5)\n",
    "# Drop the intermediate MaxSoilMoisture column if you don’t need it\n",
    "# final_df = final_df.drop(columns=['MaxSoilMoisture'])\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  MeanSoilMoisture  MeanPercolation  MeanFieldCapacity  \\\n",
      "0    2024-11-06            0.0000              0.0               0.31   \n",
      "1    2024-11-06            0.0000              0.0               0.31   \n",
      "2    2024-11-06            0.0000              0.0               0.31   \n",
      "3    2024-11-06            0.0000              0.0               0.32   \n",
      "4    2024-11-06            0.0000              0.0               0.32   \n",
      "..          ...               ...              ...                ...   \n",
      "190  2024-11-03            0.0000              0.0               0.32   \n",
      "191  2024-11-06            0.2176              0.0               0.32   \n",
      "192  2024-11-06            0.0000              0.0               0.33   \n",
      "193  2024-11-06            0.0000              0.0               0.31   \n",
      "194  2024-11-06            0.0000              0.0               0.30   \n",
      "\n",
      "              CNLNM_ID  MeanSoilMoistureWeekly  \n",
      "0             T1S1B_95                  0.0000  \n",
      "1            T2S1B_101                  0.0000  \n",
      "2            T1S1AD_46                  0.0000  \n",
      "3             T1S1D_31                  0.0000  \n",
      "4             T1S2D_49                  0.0000  \n",
      "..                 ...                     ...  \n",
      "190           S8BT_108                  0.1088  \n",
      "191           S8BT_108                  0.1088  \n",
      "192  Teesta_Canal_B_25                  0.0000  \n",
      "193  Dinajpur_Canal_68                  0.0000  \n",
      "194  Dinajpur_Canal_69                  0.0000  \n",
      "\n",
      "[195 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set the date range for the last 7 days\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.today() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Load the shapefile as a feature collection\n",
    "roi_fc = ee.FeatureCollection('users/skhan7/PhD/Chapter2/BWDB_Commad_Area_Simplified_Modified2')\n",
    "field_capacity = ee.Image(\"OpenLandMap/SOL/SOL_WATERCONTENT-33KPA_USDA-4B1C_M/v01\").select('b10').divide(ee.Number(100)).clip(roi_fc)\n",
    "\n",
    "# Initialize a list to store dataframes for each region\n",
    "region_dataframes = []\n",
    "\n",
    "# Iterate over each region (feature) in the ROI feature collection\n",
    "for region in roi_fc.toList(roi_fc.size()).getInfo():\n",
    "    region_feature = ee.Feature(region)\n",
    "    region_id = region_feature.get('CNLNM_ID').getInfo()\n",
    "    region_geometry = region_feature.geometry()\n",
    "\n",
    "    # Load Sentinel-1 Image Collection for the last 7 days and apply speckle filtering\n",
    "    s1_collection = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "                     .filterBounds(region_geometry)\n",
    "                     .filterDate(start_date, end_date)\n",
    "                     .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "                     .select(['VV']))\n",
    "\n",
    "    # Apply smoothing, calculate soil moisture, and create a feature collection for the output\n",
    "    def process_image(image):\n",
    "        # Apply focal median filter for smoothing\n",
    "        smoothed = image.addBands(image.focal_max(30, 'circle', 'meters').rename(\"Smooth\"))\n",
    "\n",
    "        # Calculate wet and dry indices using smoothed collection\n",
    "        wet_index = s1_collection.max().select('VV')\n",
    "        dry_index = s1_collection.min().select('VV')\n",
    "        sensitivity = wet_index.subtract(dry_index)\n",
    "\n",
    "        # Define urban and water masks\n",
    "        avg_vv = smoothed.select('Smooth').reduceRegion(reducer=ee.Reducer.mean(), geometry=region_geometry, scale=250)\n",
    "        urban_mask = smoothed.select('Smooth').gt(-6)\n",
    "        water_mask = smoothed.select('Smooth').lt(-17)\n",
    "\n",
    "        # Calculate soil moisture\n",
    "        Mv = smoothed.select(\"Smooth\").subtract(dry_index).divide(sensitivity)\n",
    "        Mv = Mv.updateMask(water_mask.Not()).updateMask(urban_mask.Not())\n",
    "\n",
    "        # Upscale and clamp soil moisture\n",
    "        Mv_upscaled = Mv.reduceResolution(reducer=ee.Reducer.mean(), bestEffort=True).reproject(crs=Mv.projection(), scale=250)\n",
    "        Mv_upscaled_clamped = Mv_upscaled.clamp(0, 0.6)\n",
    "\n",
    "        # Calculate mean soil moisture in the region\n",
    "        mean_ssm = Mv_upscaled_clamped.reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            geometry=region_geometry,\n",
    "            scale=250,\n",
    "            maxPixels=1e9\n",
    "        ).get('Smooth')\n",
    "\n",
    "        # Calculate field capacity\n",
    "        mean_field_capacity = field_capacity.reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            geometry=region_geometry,\n",
    "            scale=250,\n",
    "            maxPixels=1e9\n",
    "        ).get('b10')\n",
    "\n",
    "        # Calculate percolation\n",
    "        percolation = Mv_upscaled_clamped.subtract(field_capacity).max(0)\n",
    "        mean_percolation = percolation.reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            geometry=region_geometry,\n",
    "            scale=250,\n",
    "            maxPixels=1e9\n",
    "        ).get('Smooth')\n",
    "\n",
    "        \n",
    "        # Get the date of the image\n",
    "        date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd')\n",
    "        \n",
    "        # Return as a feature\n",
    "        return ee.Feature(None, {\n",
    "            'date': date,\n",
    "            'MeanSoilMoisture': mean_ssm,\n",
    "            'MeanPercolation': mean_percolation,\n",
    "            'MeanFieldCapacity': mean_field_capacity,\n",
    "            'CNLNM_ID': region_id\n",
    "        })\n",
    "\n",
    "    # Apply the processing function to each image in the smoothed collection\n",
    "    soil_moisture_features = s1_collection.map(process_image)\n",
    "\n",
    "    # Retrieve SSM, percolation, and field capacity values and create a DataFrame for each region\n",
    "    ssm_features = soil_moisture_features.getInfo()\n",
    "    week_data = [{'Date': f['properties']['date'],\n",
    "                  'MeanSoilMoisture': f['properties']['MeanSoilMoisture'],\n",
    "                  'MeanPercolation': f['properties']['MeanPercolation'],\n",
    "                  'MeanFieldCapacity': f['properties']['MeanFieldCapacity'],\n",
    "                  'CNLNM_ID': f['properties']['CNLNM_ID']} for f in ssm_features['features']]\n",
    "    \n",
    "    # Calculate the mean soil moisture over the last 7 days for each region\n",
    "    region_df = pd.DataFrame(week_data)\n",
    "    mean_ssm_week = region_df['MeanSoilMoisture'].astype(float).mean()\n",
    "    region_df['MeanSoilMoistureWeekly'] = mean_ssm_week\n",
    "    region_dataframes.append(region_df)\n",
    "\n",
    "# Combine all regional dataframes into a single DataFrame\n",
    "final_df = pd.concat(region_dataframes, ignore_index=True)\n",
    "\n",
    "# Visualize the images on the map to inspect them\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(roi_fc, 8)\n",
    "\n",
    "# Display first original and first smoothed images for visual inspection\n",
    "first_image = ee.Image(s1_collection.first())\n",
    "smoothed_first_image = first_image.addBands(first_image.focal_max(30, 'circle', 'meters').rename(\"Smooth\"))\n",
    "\n",
    "Map.addLayer(first_image, {'min': -25, 'max': 0}, \"Original VV\")\n",
    "Map.addLayer(smoothed_first_image.select(\"Smooth\"), {'min': -25, 'max': 0}, \"Smoothed VV\")\n",
    "Map\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Soil Mositure Estimation:   6%|▌         | 9/153 [05:47<1:32:46, 38.65s/Command Area]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 84\u001b[0m\n\u001b[0;32m     73\u001b[0m median_field_capacity \u001b[38;5;241m=\u001b[39m field_capacity\u001b[38;5;241m.\u001b[39mreduceRegion(\n\u001b[0;32m     74\u001b[0m     reducer\u001b[38;5;241m=\u001b[39mee\u001b[38;5;241m.\u001b[39mReducer\u001b[38;5;241m.\u001b[39mmedian(),\n\u001b[0;32m     75\u001b[0m     geometry\u001b[38;5;241m=\u001b[39mregion_geometry,\n\u001b[0;32m     76\u001b[0m     scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m,\n\u001b[0;32m     77\u001b[0m     maxPixels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e9\u001b[39m\n\u001b[0;32m     78\u001b[0m )\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb10\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Store results in a dictionary for each region\u001b[39;00m\n\u001b[0;32m     81\u001b[0m region_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNLNM_ID\u001b[39m\u001b[38;5;124m'\u001b[39m: region_id,\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedianSoilMoisture\u001b[39m\u001b[38;5;124m'\u001b[39m: median_ssm\u001b[38;5;241m.\u001b[39mgetInfo() \u001b[38;5;28;01mif\u001b[39;00m median_ssm \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedianPercolation\u001b[39m\u001b[38;5;124m'\u001b[39m: median_percolation\u001b[38;5;241m.\u001b[39mgetInfo() \u001b[38;5;28;01mif\u001b[39;00m median_percolation \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedianFieldCapacity\u001b[39m\u001b[38;5;124m'\u001b[39m: median_field_capacity\u001b[38;5;241m.\u001b[39mgetInfo() \u001b[38;5;28;01mif\u001b[39;00m median_field_capacity \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     86\u001b[0m }\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Append region data to the dataframe list\u001b[39;00m\n\u001b[0;32m     89\u001b[0m region_dataframes\u001b[38;5;241m.\u001b[39mappend(region_data)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\ee\\computedobject.py:108\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[0;32m    103\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcomputeValue(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\ee\\data.py:1082\u001b[0m, in \u001b[0;36mcomputeValue\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   1079\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[0;32m   1080\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _execute_cloud_call(\n\u001b[0;32m   1083\u001b[0m     _get_cloud_projects()\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;241m.\u001b[39mvalue()\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;241m.\u001b[39mcompute(body\u001b[38;5;241m=\u001b[39mbody, project\u001b[38;5;241m=\u001b[39m_get_projects_path(), prettyPrint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1086\u001b[0m )[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\ee\\data.py:383\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes a Cloud API call and translates errors to EEExceptions.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m  EEException if the call fails.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 383\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    385\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\googleapiclient\\http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m _retry_request(\n\u001b[0;32m    924\u001b[0m     http,\n\u001b[0;32m    925\u001b[0m     num_retries,\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sleep,\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rand,\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri),\n\u001b[0;32m    930\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod),\n\u001b[0;32m    931\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    932\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    933\u001b[0m )\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[0;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\googleapiclient\\http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m http\u001b[38;5;241m.\u001b[39mrequest(uri, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    219\u001b[0m     uri,\n\u001b[0;32m    220\u001b[0m     method,\n\u001b[0;32m    221\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    222\u001b[0m     headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[0;32m    223\u001b[0m     redirections\u001b[38;5;241m=\u001b[39mredirections,\n\u001b[0;32m    224\u001b[0m     connection_type\u001b[38;5;241m=\u001b[39mconnection_type,\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    226\u001b[0m )\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[0;32m    236\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\ee\\_cloud_api_utils.py:66\u001b[0m, in \u001b[0;36m_Http.request\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m connection_type  \u001b[38;5;66;03m# Ignored\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m redirections  \u001b[38;5;66;03m# Ignored\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m     67\u001b[0m     method, uri, data\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m     68\u001b[0m )\n\u001b[0;32m     69\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m     70\u001b[0m headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\skhan7\\anaconda3\\envs\\sdrips_env\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import geemap\n",
    "import ee\n",
    "from tqdm import tqdm \n",
    "# Initialize Earth Engine API and geemap\n",
    "ee.Initialize()\n",
    "\n",
    "# Set the date range for the last 7 days\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.today() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Load the shapefile as a feature collection\n",
    "roi_fc = ee.FeatureCollection('users/skhan7/PhD/Chapter2/BWDB_Commad_Area_Simplified_Modified2')\n",
    "field_capacity = ee.Image(\"OpenLandMap/SOL/SOL_WATERCONTENT-33KPA_USDA-4B1C_M/v01\").select('b10').divide(ee.Number(100)).clip(roi_fc)\n",
    "\n",
    "# Initialize a list to store dataframes for each region\n",
    "region_dataframes = []\n",
    "projection = ee.ImageCollection(\"COPERNICUS/S1_GRD\").select('VV').filterBounds(roi_fc).first().projection()\n",
    "# Iterate over each region (feature) in the ROI feature collection\n",
    "region_list = roi_fc.toList(roi_fc.size()).getInfo()\n",
    "for region in tqdm(region_list, desc=\"Soil Mositure Estimation\", unit=\"Command Area\"):\n",
    "    region_feature = ee.Feature(region)\n",
    "    region_id = region_feature.get('CNLNM_ID').getInfo()\n",
    "    region_geometry = region_feature.geometry()\n",
    "\n",
    "    # Load Sentinel-1 Image Collection for the last 7 days and calculate the mean image\n",
    "    s1_collection = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "                     .filterBounds(region_geometry)\n",
    "                     .filterDate(start_date, end_date)\n",
    "                     .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "                     .select(['VV']))\n",
    "\n",
    "    # Calculate mean VV for the 7-day period and apply speckle filtering\n",
    "    mean_image = s1_collection.mean().setDefaultProjection(projection)\n",
    "    smoothed = mean_image.addBands(mean_image.focal_max(30, 'circle', 'meters').rename(\"Smooth\"))\n",
    "\n",
    "    # Calculate wet and dry indices using the mean smoothed image\n",
    "    wet_index = s1_collection.max().select('VV')\n",
    "    dry_index = s1_collection.min().select('VV')\n",
    "    sensitivity = wet_index.subtract(dry_index)\n",
    "\n",
    "    # Define urban and water masks\n",
    "    urban_mask = smoothed.select('Smooth').gt(-6)\n",
    "    water_mask = smoothed.select('Smooth').lt(-17)\n",
    "\n",
    "    # Calculate soil moisture\n",
    "    Mv = smoothed.select(\"Smooth\").subtract(dry_index).divide(sensitivity)\n",
    "    Mv = Mv.updateMask(water_mask.Not()).updateMask(urban_mask.Not())\n",
    "\n",
    "    # Upscale and clamp soil moisture\n",
    "    Mv_upscaled = Mv.reduceResolution(reducer=ee.Reducer.mean(), bestEffort=True).reproject(crs=Mv.projection(), scale=250)\n",
    "    Mv_upscaled_clamped = Mv_upscaled.clamp(0, 0.6)\n",
    "\n",
    "    # Calculate mean soil moisture in the region\n",
    "    median_ssm = Mv_upscaled_clamped.reduceRegion(\n",
    "        reducer=ee.Reducer.median(),\n",
    "        geometry=region_geometry,\n",
    "        scale=250,\n",
    "        maxPixels=1e9\n",
    "    ).get('Smooth')\n",
    "\n",
    "    # Calculate percolation\n",
    "    percolation = Mv_upscaled_clamped.subtract(field_capacity).max(0)\n",
    "    median_percolation = percolation.reduceRegion(\n",
    "        reducer=ee.Reducer.median(),\n",
    "        geometry=region_geometry,\n",
    "        scale=250,\n",
    "        maxPixels=1e9\n",
    "    ).get('Smooth')\n",
    "\n",
    "    # Calculate field capacity\n",
    "    median_field_capacity = field_capacity.reduceRegion(\n",
    "        reducer=ee.Reducer.median(),\n",
    "        geometry=region_geometry,\n",
    "        scale=250,\n",
    "        maxPixels=1e9\n",
    "    ).get('b10')\n",
    "\n",
    "    # Store results in a dictionary for each region\n",
    "    region_data = {\n",
    "        'CNLNM_ID': region_id,\n",
    "        'MedianSoilMoisture': median_ssm.getInfo() if median_ssm else None,\n",
    "        'MedianPercolation': median_percolation.getInfo() if median_percolation else None,\n",
    "        'MedianFieldCapacity': median_field_capacity.getInfo() if median_field_capacity else None\n",
    "    }\n",
    "    \n",
    "    # Append region data to the dataframe list\n",
    "    region_dataframes.append(region_data)\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "final_df = pd.DataFrame(region_dataframes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating Soil Mositure: 100%|██████████| 153/153 [01:08<00:00,  2.22 Command Area/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               CNLNM_ID  MedianSoilMoisture  MedianFieldCapacity  \\\n",
      "0       Bogra_Canal_104                 0.3                 0.28   \n",
      "1        Bogra_Canal_78                 0.0                 0.30   \n",
      "2        Bogra_Canal_92                 0.0                 0.31   \n",
      "3    Dinajpur_Canal_123                 0.0                 0.28   \n",
      "4     Dinajpur_Canal_21                 0.0                 0.33   \n",
      "..                  ...                 ...                  ...   \n",
      "148   Teesta_Canal_A_13                 0.0                 0.32   \n",
      "149   Teesta_Canal_A_16                 0.0                 0.32   \n",
      "150    Teesta_Canal_A_4                 0.0                 0.33   \n",
      "151   Teesta_Canal_B_18                 0.0                 0.32   \n",
      "152   Teesta_Canal_B_25                 0.0                 0.33   \n",
      "\n",
      "     MedianPercolation  \n",
      "0                 0.02  \n",
      "1                 0.00  \n",
      "2                 0.00  \n",
      "3                 0.00  \n",
      "4                 0.00  \n",
      "..                 ...  \n",
      "148               0.00  \n",
      "149               0.00  \n",
      "150               0.00  \n",
      "151               0.00  \n",
      "152               0.00  \n",
      "\n",
      "[153 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import geemap\n",
    "import ee\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize Earth Engine API and geemap\n",
    "ee.Initialize()\n",
    "\n",
    "# Set the date range for the last 7 days\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.today() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Load the shapefile as a feature collection\n",
    "roi_fc = ee.FeatureCollection('users/skhan7/PhD/Chapter2/BWDB_Commad_Area_Simplified_Modified2')\n",
    "field_capacity = ee.Image(\"OpenLandMap/SOL/SOL_WATERCONTENT-33KPA_USDA-4B1C_M/v01\").select('b10').divide(ee.Number(100)).clip(roi_fc)\n",
    "\n",
    "# Initialize a list to store dataframes for each region\n",
    "region_dataframes = []\n",
    "\n",
    "# Use tqdm to add a progress bar for the number of regions\n",
    "region_list = roi_fc.toList(roi_fc.size()).getInfo()\n",
    "for region in tqdm(region_list, desc=\"Estimating Soil Mositure\", unit=\" Command Area\"):\n",
    "    region_feature = ee.Feature(region)\n",
    "    region_id = region_feature.get('CNLNM_ID').getInfo()\n",
    "    region_geometry = region_feature.geometry()\n",
    "\n",
    "    # Load Sentinel-1 Image Collection for the last 7 days and apply speckle filtering\n",
    "    s1_collection = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "                     .filterBounds(region_geometry)\n",
    "                     .filterDate(start_date, end_date)\n",
    "                     .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "                     .select(['VV']))\n",
    "\n",
    "    # Apply smoothing, calculate soil moisture, and create a feature collection for the output\n",
    "    def process_image(image):\n",
    "        # Apply focal median filter for smoothing\n",
    "        smoothed = image.addBands(image.focal_max(30, 'circle', 'meters').rename(\"Smooth\"))\n",
    "\n",
    "        # Calculate wet and dry indices using smoothed collection\n",
    "        wet_index = s1_collection.max().select('VV')\n",
    "        dry_index = s1_collection.min().select('VV')\n",
    "        sensitivity = wet_index.subtract(dry_index)\n",
    "\n",
    "        # Define urban and water masks\n",
    "        urban_mask = smoothed.select('Smooth').gt(-6)\n",
    "        water_mask = smoothed.select('Smooth').lt(-17)\n",
    "\n",
    "        # Calculate soil moisture\n",
    "        Mv = smoothed.select(\"Smooth\").subtract(dry_index).divide(sensitivity)\n",
    "        Mv = Mv.updateMask(water_mask.Not()).updateMask(urban_mask.Not())\n",
    "\n",
    "        # Upscale and clamp soil moisture\n",
    "        Mv_upscaled = Mv.reduceResolution(reducer=ee.Reducer.mean(), bestEffort=True).reproject(crs=Mv.projection(), scale=250)\n",
    "        Mv_upscaled_clamped = Mv_upscaled.clamp(0, 0.6)\n",
    "\n",
    "        # Calculate mean soil moisture in the region\n",
    "        median_ssm = Mv_upscaled_clamped.reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            geometry=region_geometry,\n",
    "            scale=250,\n",
    "            maxPixels=1e9\n",
    "        ).get('Smooth')\n",
    "\n",
    "        # Calculate field capacity\n",
    "        median_field_capacity = field_capacity.reduceRegion(\n",
    "            reducer=ee.Reducer.median(),\n",
    "            geometry=region_geometry,\n",
    "            scale=250,\n",
    "            maxPixels=1e9\n",
    "        ).get('b10')\n",
    "\n",
    "        # # Calculate percolation\n",
    "        # percolation = Mv_upscaled_clamped.subtract(field_capacity).max(0)\n",
    "        # median_percolation = percolation.reduceRegion(\n",
    "        #     reducer=ee.Reducer.median(),\n",
    "        #     geometry=region_geometry,\n",
    "        #     scale=250,\n",
    "        #     maxPixels=1e9\n",
    "        # ).get('Smooth')\n",
    "\n",
    "        # Return as a feature with aggregated data for the period\n",
    "        return ee.Feature(None, {\n",
    "            'CNLNM_ID': region_id,\n",
    "            'MedianSoilMoisture': median_ssm,\n",
    "            'MedianFieldCapacity': median_field_capacity\n",
    "        })\n",
    "\n",
    "    # Apply the processing function to each image in the smoothed collection\n",
    "    soil_moisture_features = s1_collection.map(process_image)\n",
    "\n",
    "    # Retrieve data for each region and create a DataFrame\n",
    "    ssm_features = soil_moisture_features.getInfo()\n",
    "    week_data = [{'CNLNM_ID': f['properties']['CNLNM_ID'],\n",
    "                  'MedianSoilMoisture': f['properties']['MedianSoilMoisture'],\n",
    "                  'MedianFieldCapacity': f['properties']['MedianFieldCapacity']}\n",
    "                 for f in ssm_features['features']]\n",
    "    \n",
    "    # Append the data for the current region to the list\n",
    "    region_df = pd.DataFrame(week_data)\n",
    "    region_dataframes.append(region_df)\n",
    "\n",
    "# Combine all regional dataframes into a single DataFrame\n",
    "final_df = pd.concat(region_dataframes, ignore_index=True)\n",
    "# Group by region and calculate the mean values for each metric\n",
    "final_means_df = final_df.groupby('CNLNM_ID').mean().reset_index()\n",
    "final_means_df['MedianPercolation'] = (final_means_df['MedianSoilMoisture'] - final_means_df['MedianFieldCapacity']).clip(lower=0)\n",
    "# Print the final DataFrame with mean values for each region\n",
    "print(final_means_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the final DataFrame\n",
    "print(final_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdrips_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
